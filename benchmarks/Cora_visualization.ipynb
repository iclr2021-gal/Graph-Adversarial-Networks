{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from torch_geometric.utils import (negative_sampling, remove_self_loops,\n",
    "                                   add_self_loops)\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, ChebConv, GINConv, GATConv  # noqa\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import json\n",
    "from torch.nn import Sequential, ReLU, Linear\n",
    "\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Implement the gradient reversal layer for the convenience of domain adaptation neural network.\n",
    "    The forward part is the identity function while the backward part is the negative function.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg()\n",
    "\n",
    "class GradientReversalLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GradientReversalLayer, self).__init__()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return GradReverse.apply(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sim(lambda_reg):\n",
    "    class Net(torch.nn.Module):\n",
    "        def __init__(self, name='GCNConv'):\n",
    "            super(Net, self).__init__()\n",
    "            self.name = name\n",
    "            if (name == 'GCNConv'):\n",
    "                self.conv1 = GCNConv(dataset.num_features, 128)\n",
    "                self.conv2 = GCNConv(128, 64)\n",
    "            elif (name == 'ChebConv'):\n",
    "                self.conv1 = ChebConv(dataset.num_features, 128, K=2)\n",
    "                self.conv2 = ChebConv(128, 64, K=2)\n",
    "            elif (name == 'GATConv'):\n",
    "                self.conv1 = GATConv(dataset.num_features, 128)\n",
    "                self.conv2 = GATConv(128, 64)\n",
    "            elif (name == 'GINConv'):\n",
    "                nn1 = Sequential(Linear(dataset.num_features, 128), ReLU(), Linear(128, 64))\n",
    "                self.conv1 = GINConv(nn1)\n",
    "                self.bn1 = torch.nn.BatchNorm1d(64)\n",
    "                nn2 = Sequential(Linear(64, 64), ReLU(), Linear(64, 64))\n",
    "                self.conv2 = GINConv(nn2)\n",
    "                self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "\n",
    "            self.attr = GCNConv(64, dataset.num_classes, cached=True,\n",
    "                                    normalize=not gdc)\n",
    "\n",
    "            self.attack = GCNConv(64, dataset.num_classes, cached=True,\n",
    "                                normalize=not gdc)\n",
    "            self.reverse = GradientReversalLayer()\n",
    "\n",
    "        def forward(self, pos_edge_index, neg_edge_index):\n",
    "\n",
    "            if (self.name == 'GINConv'):\n",
    "                x = F.relu(self.conv1(data.x, data.train_pos_edge_index))\n",
    "                x = self.bn1(x)\n",
    "                x = F.relu(self.conv2(x, data.train_pos_edge_index))\n",
    "                x = self.bn2(x)\n",
    "            else:\n",
    "                x = F.relu(self.conv1(data.x, data.train_pos_edge_index))\n",
    "                x = self.conv2(x, data.train_pos_edge_index)\n",
    "\n",
    "            feat = x\n",
    "            attr = self.attr(x, edge_index, edge_weight)\n",
    "\n",
    "            #print(feat.size())\n",
    "            attack = self.reverse(x)\n",
    "            att = self.attack(attack, edge_index, edge_weight)\n",
    "\n",
    "            total_edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1)\n",
    "            x_j = torch.index_select(x, 0, total_edge_index[0])\n",
    "            x_i = torch.index_select(x, 0, total_edge_index[1])\n",
    "\n",
    "            \"\"\"\n",
    "            print(x_j.size())\n",
    "            print(x_i.size())\n",
    "            \"\"\"\n",
    "\n",
    "            res = torch.einsum(\"ef,ef->e\", x_i, x_j)\n",
    "\n",
    "            #print(res.size())\n",
    "            return res, F.log_softmax(attr, dim=1), F.log_softmax(att, dim=1), feat\n",
    "    \n",
    "    m = 'GATConv' \n",
    "    seed = 42\n",
    "    lr = 0.01\n",
    "    num_epochs = 100 if lambda_reg==0 else 175\n",
    "    finetune_epochs = 40\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    dataset = \"Cora\"\n",
    "    path = osp.join('..', 'data', dataset)\n",
    "    dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "    data = dataset[0]\n",
    "    gdc = False\n",
    "    if gdc:\n",
    "        gdc = T.GDC(self_loop_weight=1, normalization_in='sym',\n",
    "                    normalization_out='col',\n",
    "                    diffusion_kwargs=dict(method='ppr', alpha=0.05),\n",
    "                    sparsification_kwargs=dict(method='topk', k=128,\n",
    "                                            dim=0), exact=True)\n",
    "        data = gdc(data)\n",
    "\n",
    "    labels = data.y.cuda()\n",
    "    edge_index, edge_weight = data.edge_index.cuda(), data.edge_attr\n",
    "\n",
    "    print(labels.size())\n",
    "    # Train/validation/test\n",
    "    data = train_test_split_edges(data)\n",
    "\n",
    "    print(labels)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    model, data = Net(m).cuda(), data.to(\"cuda\")\n",
    "\n",
    "    if (m=='GINConv'):\n",
    "        optimizer = torch.optim.Adam([\n",
    "            dict(params=model.conv1.parameters(), weight_decay=0),\n",
    "            dict(params=model.bn1.parameters(), weight_decay=0),\n",
    "            dict(params=model.conv2.parameters(), weight_decay=0),\n",
    "            dict(params=model.bn2.parameters(), weight_decay=0),\n",
    "        ], lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam([\n",
    "            dict(params=model.conv1.parameters(), weight_decay=0),\n",
    "            dict(params=model.conv2.parameters(), weight_decay=0)\n",
    "        ], lr=lr)\n",
    "\n",
    "    if (m=='GINConv'):\n",
    "        optimizer_att = torch.optim.Adam([\n",
    "            dict(params=model.conv2.parameters(), weight_decay=5e-4), \n",
    "            dict(params=model.bn2.parameters(), weight_decay=0),  \n",
    "            dict(params=model.attack.parameters(), weight_decay=5e-4),\n",
    "        ], lr=lr * lambda_reg)\n",
    "    else:\n",
    "        optimizer_att = torch.optim.Adam([\n",
    "            dict(params=model.conv2.parameters(), weight_decay=5e-4),   \n",
    "            dict(params=model.attack.parameters(), weight_decay=5e-4),\n",
    "        ], lr=lr * lambda_reg)\n",
    "\n",
    "    def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "        link_labels = torch.zeros(pos_edge_index.size(1) +\n",
    "                                neg_edge_index.size(1)).float().to(device)\n",
    "        link_labels[:pos_edge_index.size(1)] = 1.\n",
    "        return link_labels\n",
    "\n",
    "\n",
    "    def train():\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, pos_edge_index = data.x, data.train_pos_edge_index\n",
    "\n",
    "        _edge_index, _ = remove_self_loops(pos_edge_index)\n",
    "        pos_edge_index_with_self_loops, _ = add_self_loops(_edge_index,\n",
    "                                                        num_nodes=x.size(0))\n",
    "\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=pos_edge_index_with_self_loops, num_nodes=x.size(0),\n",
    "            num_neg_samples=pos_edge_index.size(1))\n",
    "\n",
    "        link_logits, attr_prediction, attack_prediction,_ = model(pos_edge_index, neg_edge_index)\n",
    "        link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(link_logits, link_labels)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer_att.zero_grad()\n",
    "        loss2 = F.nll_loss(attack_prediction, labels)\n",
    "        loss2.backward()\n",
    "        optimizer_att.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def test():\n",
    "        model.eval()\n",
    "        perfs = []\n",
    "        for prefix in [\"val\", \"test\"]:\n",
    "            pos_edge_index, neg_edge_index = [\n",
    "                index for _, index in data(\"{}_pos_edge_index\".format(prefix),\n",
    "                                        \"{}_neg_edge_index\".format(prefix))\n",
    "            ]\n",
    "            link_probs = torch.sigmoid(model(pos_edge_index, neg_edge_index)[0])\n",
    "            link_labels = get_link_labels(pos_edge_index, neg_edge_index)\n",
    "            link_probs = link_probs.detach().cpu().numpy()\n",
    "            link_labels = link_labels.detach().cpu().numpy()\n",
    "            perfs.append(roc_auc_score(link_labels, link_probs))\n",
    "        return perfs\n",
    "\n",
    "\n",
    "    best_val_perf = test_perf = 0\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_loss = train()\n",
    "        val_perf, tmp_test_perf = test()\n",
    "        if val_perf > best_val_perf:\n",
    "            best_val_perf = val_perf\n",
    "            test_perf = tmp_test_perf\n",
    "        log = 'Epoch: {:03d}, Loss: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "        print(log.format(epoch, train_loss, val_perf, tmp_test_perf))\n",
    "\n",
    "\n",
    "    optimizer_attr = torch.optim.Adam([\n",
    "        dict(params=model.attr.parameters(), weight_decay=5e-4),\n",
    "    ], lr=lr)\n",
    "\n",
    "    def train_attr():\n",
    "        model.train()\n",
    "        optimizer_attr.zero_grad()\n",
    "\n",
    "        x, pos_edge_index = data.x, data.train_pos_edge_index\n",
    "\n",
    "        _edge_index, _ = remove_self_loops(pos_edge_index)\n",
    "        pos_edge_index_with_self_loops, _ = add_self_loops(_edge_index,\n",
    "                                                        num_nodes=x.size(0))\n",
    "\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=pos_edge_index_with_self_loops, num_nodes=x.size(0),\n",
    "            num_neg_samples=pos_edge_index.size(1))\n",
    "\n",
    "        F.nll_loss(model(pos_edge_index, neg_edge_index)[1][data.train_mask], labels[data.train_mask]).backward()\n",
    "        optimizer_attr.step()\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test_attr():\n",
    "        model.eval()\n",
    "        accs = []\n",
    "        m = ['train_mask', 'val_mask', 'test_mask']\n",
    "        i = 0\n",
    "        for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "\n",
    "            if (m[i] == 'train_mask') :\n",
    "                x, pos_edge_index = data.x, data.train_pos_edge_index\n",
    "\n",
    "                _edge_index, _ = remove_self_loops(pos_edge_index)\n",
    "                pos_edge_index_with_self_loops, _ = add_self_loops(_edge_index,\n",
    "                                                                num_nodes=x.size(0))\n",
    "\n",
    "                neg_edge_index = negative_sampling(\n",
    "                    edge_index=pos_edge_index_with_self_loops, num_nodes=x.size(0),\n",
    "                    num_neg_samples=pos_edge_index.size(1))\n",
    "            else:\n",
    "                pos_edge_index, neg_edge_index = [\n",
    "                index for _, index in data(\"{}_pos_edge_index\".format(m[i].split(\"_\")[0]),\n",
    "                                        \"{}_neg_edge_index\".format(m[i].split(\"_\")[0]))\n",
    "                ]\n",
    "            _, logits, _, _ = model(pos_edge_index, neg_edge_index)\n",
    "\n",
    "            pred = logits[mask].max(1)[1]\n",
    "            #acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
    "            #accs.append(acc)\n",
    "\n",
    "            macro = f1_score((data.y[mask]).cpu().numpy(), pred.cpu().numpy(),average='macro')\n",
    "            accs.append(macro)\n",
    "\n",
    "            i+=1\n",
    "        return accs\n",
    "\n",
    "    if True:\n",
    "        best_val_acc = test_acc = 0\n",
    "        for epoch in range(1, finetune_epochs+1):\n",
    "            train_attr()\n",
    "            train_acc, val_acc, tmp_test_acc = test_attr()\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                test_acc = tmp_test_acc\n",
    "            log = 'Epoch: {:03d}, Train: {:.4f}, Val: {:.4f}, Test: {:.4f}'\n",
    "            print(log.format(epoch, train_acc, val_acc, tmp_test_acc))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_135 = sim(1.3)\n",
    "model_1 = sim(1.2)\n",
    "model_0 = sim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(model):\n",
    "    model.train()\n",
    "    \n",
    "    dataset = \"Cora\"\n",
    "    path = osp.join('..', 'data', dataset)\n",
    "    dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "    data = dataset[0]\n",
    "    gdc = False\n",
    "    if gdc:\n",
    "        gdc = T.GDC(self_loop_weight=1, normalization_in='sym',\n",
    "                    normalization_out='col',\n",
    "                    diffusion_kwargs=dict(method='ppr', alpha=0.05),\n",
    "                    sparsification_kwargs=dict(method='topk', k=128,\n",
    "                                            dim=0), exact=True)\n",
    "        data = gdc(data)\n",
    "\n",
    "    labels = data.y.cuda()\n",
    "    edge_index, edge_weight = data.edge_index.cuda(), data.edge_attr\n",
    "\n",
    "    print(labels.size())\n",
    "    # Train/validation/test\n",
    "    data = train_test_split_edges(data)\n",
    "    \n",
    "    x, pos_edge_index = data.x, data.train_pos_edge_index\n",
    "\n",
    "    _edge_index, _ = remove_self_loops(pos_edge_index)\n",
    "    pos_edge_index_with_self_loops, _ = add_self_loops(_edge_index,\n",
    "                                                    num_nodes=x.size(0))\n",
    "\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=pos_edge_index_with_self_loops, num_nodes=x.size(0),\n",
    "        num_neg_samples=pos_edge_index.size(1))\n",
    "\n",
    "    return model(pos_edge_index.cuda(), neg_edge_index.cuda())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat0 = feat(model_0)\n",
    "feat1 = feat(model_1)\n",
    "feat135 = feat(model_135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Cora\"\n",
    "path = osp.join('..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "labels = data.y.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=100, n_iter=1300)\n",
    "tsne_0 = tsne.fit_transform(feat0.cpu().detach().numpy())\n",
    "tsne_1 = tsne.fit_transform(feat1.cpu().detach().numpy())\n",
    "tsne_135 = tsne.fit_transform(feat135.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "sns.set_style(\"dark\")\n",
    "sns.set(rc={'figure.figsize':(8,8)})\n",
    "palette = sns.color_palette(\"bright\", 7)\n",
    "ax = sns.scatterplot(tsne_results[:,0], tsne_results[:,1], hue=lab.detach().cpu().numpy(), legend='full', palette=palette)\n",
    "ax.grid(False)\n",
    "ax.patch.set_facecolor('white')\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "dataset = \"Cora\"\n",
    "path = osp.join('..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset)\n",
    "data = dataset[0]\n",
    "el = data.edge_index.cpu().numpy()\n",
    "G = nx.Graph([(el[0,i],el[1,i]) for i in range(el.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos0 = {}\n",
    "for i in range(2708):\n",
    "    pos0[i]=[tsne_0[i,0],tsne_0[i,1]]\n",
    "    \n",
    "pos135 = {}\n",
    "for i in range(2708):\n",
    "    pos135[i]=[tsne_135[i,0],tsne_135[i,1]]\n",
    "    \n",
    "pos1 = {}\n",
    "for i in range(2708):\n",
    "    pos1[i]=[tsne_1[i,0],tsne_1[i,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20,10)})\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "\n",
    "palette = sns.color_palette(\"tab20\",7)\n",
    "nx.draw_networkx_edges(G, pos0, alpha=0.1,edge_color='b',style='solid',ax=axs[0])\n",
    "sns.scatterplot(tsne_0[:,0], tsne_0[:,1], hue=labels, legend=None, palette=palette,ax=axs[0],s=70, edgecolor=\"black\")\n",
    "\n",
    "axs[0].grid(False)\n",
    "axs[0].patch.set_facecolor('white')\n",
    "axs[0].set(xticks=[],yticks=[])\n",
    "axs[0].set_xlabel(r'$\\lambda = 0$', fontsize=17)\n",
    "\n",
    "\"\"\"\n",
    "nx.draw_networkx_edges(G, pos1, alpha=0.1,edge_color='b',style='solid',ax=axs[1])\n",
    "sns.scatterplot(tsne_1[:,0], tsne_1[:,1], hue=labels, legend=None, palette=palette,ax=axs[1],s=70, edgecolor=\"black\")\n",
    "\n",
    "axs[1].grid(False)\n",
    "axs[1].patch.set_facecolor('white')\n",
    "axs[1].set(xticks=[],yticks=[])\n",
    "axs[1].set_xlabel(r'$\\lambda = 1.2$', fontsize=17)\n",
    "\"\"\"\n",
    "\n",
    "nx.draw_networkx_edges(G, pos135, alpha=0.1,edge_color='b',style='solid',ax=axs[1])\n",
    "sns.scatterplot(tsne_135[:,0], tsne_135[:,1], hue=labels, legend=None, palette=palette,ax=axs[1],s=70, edgecolor=\"black\")\n",
    "\n",
    "axs[1].grid(False)\n",
    "axs[1].patch.set_facecolor('white')\n",
    "axs[1].set(xticks=[],yticks=[])\n",
    "axs[1].set_xlabel(r'$\\lambda = 1.3$', fontsize=17)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('cora.pdf', bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Cora\"\n",
    "path = osp.join('..', 'data', dataset)\n",
    "dataset = Planetoid(path, dataset, T.NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
